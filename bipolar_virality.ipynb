{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bipolar-virality.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWqLFgl280DhmuCIgFjA9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supreet21/likelihood-of-news-virality/blob/master/bipolar_virality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnPpPeRG-Aq3",
        "colab_type": "code",
        "outputId": "ffef0618-1dcf-46cf-e7b3-8c3e3fd38a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 33.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 34.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 18.2MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 12.9MB/s \n",
            "\u001b[?25hCollecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (46.1.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2.1->newspaper3k) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Building wheels for collected packages: feedparser, jieba3k, tinysegmenter, feedfinder2\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=b1a13ee9f33100133284b4865e218c17ecb15a8ebe02f86eeda797a129951c2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=00b46e3483c2723d1af4e8186692ae5606054c3de08ebdcddd8d3967121b0621\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=9eb0a00d27a10f5693f992f178649717da731b3af4529d27263f7eadb562db8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=82eb2beb08fea3da8a5bf6d8ec6fdf9085239db389f30e07199a756d11a4c841\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "Successfully built feedparser jieba3k tinysegmenter feedfinder2\n",
            "Installing collected packages: requests-file, tldextract, feedparser, jieba3k, tinysegmenter, cssselect, feedfinder2, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUxBLO4Q8gss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article  \n",
        "import csv \n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbMlF38w_Oot",
        "colab_type": "text"
      },
      "source": [
        "## Crawling News from Times of India Website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-oc3vQQ9ZwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://timesofindia.indiatimes.com/world\"\n",
        "r = requests.get(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVRWRa3Q9dnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(r.content, 'html5lib') \n",
        "table = soup.findAll('a', attrs = {'class':'w_img'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJWmdzuU-pUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "news=[]\n",
        "for row in table: \n",
        "    if not row['href'].startswith('http'):\n",
        "        news.append('https://timesofindia.indiatimes.com'+row['href'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpscNVMZ-suN",
        "colab_type": "code",
        "outputId": "429d4677-d714-4063-8d1d-8c7f2fc6077f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "  \n",
        "df=[]\n",
        "for i in news:\n",
        "    article = Article(i, language=\"en\")\n",
        "    article.download() \n",
        "    article.parse() \n",
        "    article.nlp() \n",
        "    data={}\n",
        "    data['Title']=article.title\n",
        "    data['Text']=article.text\n",
        "    data['Summary']=article.summary\n",
        "    data['Keywords']=article.keywords\n",
        "    df.append(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OZd1GSt-yHg",
        "colab_type": "code",
        "outputId": "8e893411-6738-4892-b239-93af66daaf60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "dataset=pd.DataFrame(df)\n",
        "dataset.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France Lockdown Lift: France to outline plans ...</td>\n",
              "      <td>Nurse Sandrine poses as she works in a hotel o...</td>\n",
              "      <td>Restaurants, cafes and cinemas will have to re...</td>\n",
              "      <td>[lift, lawmakers, lockdown, told, plans, numbe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Covid-19: Testing won't 'be a problem' for reo...</td>\n",
              "      <td>Apr 28, 2020, 08:40AM IST\\n\\nSource: AP\\n\\nThe...</td>\n",
              "      <td>Apr 28, 2020, 08:40AM ISTSource: APThe White H...</td>\n",
              "      <td>[white, unveiling, wont, reopening, house, tes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Covid-19: Some Georgia restaurants reopen for ...</td>\n",
              "      <td>Apr 28, 2020, 08:43AM IST\\n\\nSource: AP\\n\\nWit...</td>\n",
              "      <td>Apr 28, 2020, 08:43AM ISTSource: APWith tables...</td>\n",
              "      <td>[georgia, covid19, wearing, allowed, dinein, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'Very good idea' on Kim Jong Un's health: Pres...</td>\n",
              "      <td>Apr 28, 2020, 08:39AM IST\\n\\nSource: AP\\n\\nNor...</td>\n",
              "      <td>Apr 28, 2020, 08:39AM ISTSource: APNorth Korea...</td>\n",
              "      <td>[good, korean, uns, jong, idea, health, speaki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Covid-19: Mayor entertains residents after imp...</td>\n",
              "      <td>Apr 27, 2020, 08:27AM IST\\n\\nSource: AP\\n\\nThe...</td>\n",
              "      <td>Apr 27, 2020, 08:27AM ISTSource: APThe videos,...</td>\n",
              "      <td>[curfew, videos, facebook, mayor, community, c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                           Keywords\n",
              "0  France Lockdown Lift: France to outline plans ...  ...  [lift, lawmakers, lockdown, told, plans, numbe...\n",
              "1  Covid-19: Testing won't 'be a problem' for reo...  ...  [white, unveiling, wont, reopening, house, tes...\n",
              "2  Covid-19: Some Georgia restaurants reopen for ...  ...  [georgia, covid19, wearing, allowed, dinein, c...\n",
              "3  'Very good idea' on Kim Jong Un's health: Pres...  ...  [good, korean, uns, jong, idea, health, speaki...\n",
              "4  Covid-19: Mayor entertains residents after imp...  ...  [curfew, videos, facebook, mayor, community, c...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHwcA2OpAxw_",
        "colab_type": "text"
      },
      "source": [
        "# collecting the dataset to train on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Fg6FvpA2of",
        "colab_type": "code",
        "outputId": "83c3ab39-d351-4d45-bb89-b00c9275dd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 14:39:15--  http://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7476401 (7.1M) [application/x-httpd-php]\n",
            "Saving to: ‘OnlineNewsPopularity.zip’\n",
            "\n",
            "\rOnlineNewsPopularit   0%[                    ]       0  --.-KB/s               \rOnlineNewsPopularit  11%[=>                  ] 865.96K  3.89MB/s               \rOnlineNewsPopularit 100%[===================>]   7.13M  22.6MB/s    in 0.3s    \n",
            "\n",
            "2020-04-28 14:39:16 (22.6 MB/s) - ‘OnlineNewsPopularity.zip’ saved [7476401/7476401]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx79enf6A4qX",
        "colab_type": "code",
        "outputId": "2bd129f5-b54f-4250-e536-582a4c4df49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip OnlineNewsPopularity.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  OnlineNewsPopularity.zip\n",
            "   creating: OnlineNewsPopularity/\n",
            "  inflating: OnlineNewsPopularity/OnlineNewsPopularity.names  \n",
            "  inflating: OnlineNewsPopularity/OnlineNewsPopularity.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa3WRAa0_UfO",
        "colab_type": "text"
      },
      "source": [
        "## Model for predicting virality of news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPai8hZJ--xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJycIbv3_b7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILEPATH=\"/content/OnlineNewsPopularity/OnlineNewsPopularity.csv\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TORJB3r_kPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_cols(data):\n",
        "    \"\"\"Clean the column names by stripping and lowercase.\"\"\"\n",
        "    clean_col_map = {x: x.lower().strip() for x in list(data)}\n",
        "    return data.rename(index=str, columns=clean_col_map)\n",
        "\n",
        "def TrainTestSplit(X, Y, R=0, test_size=0.2):\n",
        "    \"\"\"Easy Train Test Split call.\"\"\"\n",
        "    return train_test_split(X, Y, test_size=test_size, random_state=R)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cor3Na9M_nUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_data = clean_cols(pd.read_csv(FILEPATH))\n",
        "train_set, test_set = train_test_split(full_data, test_size=0.20, random_state=42)\n",
        "\n",
        "x_train = train_set.drop(['url','shares', 'timedelta', 'lda_00','lda_01','lda_02','lda_03','lda_04','num_self_hrefs', 'kw_min_min', 'kw_max_min', 'kw_avg_min','kw_min_max','kw_max_max','kw_avg_max','kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','rate_positive_words','rate_negative_words','abs_title_subjectivity','abs_title_sentiment_polarity'], axis=1)\n",
        "y_train = train_set['shares']\n",
        "\n",
        "x_test = test_set.drop(['url','shares', 'timedelta', 'num_self_hrefs', 'kw_min_min', 'kw_max_min', 'kw_avg_min','kw_min_max','kw_max_max','kw_avg_max','kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','rate_positive_words','rate_negative_words','abs_title_subjectivity','abs_title_sentiment_polarity'], axis=1)\n",
        "y_test = test_set['shares']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAdvf5Zc_sZS",
        "colab_type": "code",
        "outputId": "ae162ff6-f978-4f6c-90a5-72dbd7dd2c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "clf = RandomForestRegressor(random_state=42)\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PUal_XSBPJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_res = pd.DataFrame(clf.predict(x_train),list(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OMthe4mBRp4",
        "colab_type": "code",
        "outputId": "8f6f5e1f-ac59-4b53-a84b-6e45208aaca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rf_res.reset_index(level=0, inplace=True)\n",
        "rf_res_df = rf_res.rename(index=str, columns={\"index\": \"Actual shares\", 0: \"Predicted shares\"})\n",
        "rf_res_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual shares</th>\n",
              "      <th>Predicted shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16100</td>\n",
              "      <td>11247.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>508</td>\n",
              "      <td>882.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1300</td>\n",
              "      <td>1864.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3100</td>\n",
              "      <td>3627.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6900</td>\n",
              "      <td>5415.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Actual shares  Predicted shares\n",
              "0          16100          11247.11\n",
              "1            508            882.22\n",
              "2           1300           1864.97\n",
              "3           3100           3627.22\n",
              "4           6900           5415.02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_uLD6O5BXJ6",
        "colab_type": "text"
      },
      "source": [
        "## Converting Crawled News according to Training Set in UCI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur_vJG4LBTxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7917297-3263-49c4-eb58-ac5f9b986a86"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "stopwords=set(stopwords.words('english'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob4moncsBgSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rate_unique(words):\n",
        "    words=tokenize(words)\n",
        "    no_order = list(set(words))\n",
        "    rate_unique=len(no_order)/len(words)\n",
        "    return rate_unique"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kurLsgM-BgpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rate_nonstop(words):\n",
        "    words1=tokenize(words)\n",
        "    filtered_sentence = [w for w in words1 if not w in stopwords]\n",
        "    rate_nonstop=len(filtered_sentence)/len(words1)\n",
        "    no_order = list(set(filtered_sentence))\n",
        "    rate_unique_nonstop=len(no_order)/len(words1)\n",
        "    return rate_nonstop,rate_unique_nonstop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOX01Qt0Blev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def avg_token(words):\n",
        "    words=tokenize(words)\n",
        "    length=[]\n",
        "    for i in words:\n",
        "        length.append(len(i))\n",
        "    return np.average(length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYrhiLVwBpV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MklFzsViBxRN",
        "colab_type": "code",
        "outputId": "714bc3c4-6751-47be-fdc7-9915200ac16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install datefinder\n",
        "!pip install datetime"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datefinder in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from datefinder) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datefinder) (2018.9)\n",
            "Requirement already satisfied: regex>=2017.02.08 in /usr/local/lib/python3.6/dist-packages (from datefinder) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.4.2->datefinder) (1.12.0)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.6/dist-packages (4.3)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from datetime) (5.1.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datetime) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zope.interface->datetime) (46.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbSsfkBJBt6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import datefinder\n",
        "import datetime  \n",
        "from datetime import date \n",
        "def day(article_text):\n",
        "    article=article_text\n",
        "    if len(list(datefinder.find_dates(article)))>0:\n",
        "        date=str(list(datefinder.find_dates(article))[0])\n",
        "        date=date.split()\n",
        "        date=date[0]\n",
        "        year, month, day = date.split('-')     \n",
        "        day_name = datetime.date(int(year), int(month), int(day)) \n",
        "        return day_name.strftime(\"%A\")\n",
        "    return \"Monday\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLHqbzQRBuUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tokenize(text):\n",
        "    text=text\n",
        "    return word_tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv2hiwkWB-Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_words=[]\n",
        "neg_words=[]\n",
        "def polar(words):\n",
        "    all_tokens=tokenize(words)\n",
        "    for i in all_tokens:\n",
        "        analysis=TextBlob(i)\n",
        "        polarity=analysis.sentiment.polarity\n",
        "        if polarity>0:\n",
        "            pos_words.append(i)\n",
        "        if polarity<0:\n",
        "            neg_words.append(i)\n",
        "    return pos_words,neg_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWWzsQLyB-rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rates(words):\n",
        "    words=polar(words)\n",
        "    pos=words[0]\n",
        "    neg=words[1]\n",
        "    all_words=words\n",
        "    global_rate_positive_words=(len(pos)/len(all_words))/100\n",
        "    global_rate_negative_words=(len(neg)/len(all_words))/100\n",
        "    pol_pos=[]\n",
        "    pol_neg=[]\n",
        "    for i in pos:\n",
        "        analysis=TextBlob(i)\n",
        "        pol_pos.append(analysis.sentiment.polarity)\n",
        "        avg_positive_polarity=analysis.sentiment.polarity\n",
        "    for j in neg:\n",
        "        analysis2=TextBlob(j)\n",
        "        pol_neg.append(analysis2.sentiment.polarity)\n",
        "        avg_negative_polarity=analysis2.sentiment.polarity\n",
        "    min_positive_polarity=min(pol_pos)\n",
        "    max_positive_polarity=max(pol_pos)\n",
        "    min_negative_polarity=min(pol_neg)\n",
        "    max_negative_polarity=max(pol_neg)\n",
        "    avg_positive_polarity=np.average(pol_pos)\n",
        "    avg_negative_polarity=np.average(pol_neg)\n",
        "    return global_rate_positive_words,global_rate_negative_words,avg_positive_polarity,min_positive_polarity,max_positive_polarity,avg_negative_polarity,min_negative_polarity,max_negative_polarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HiAG0MPCGSn",
        "colab_type": "code",
        "outputId": "30d23ae3-7756-4fab-c7fd-a2117ee00a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "df2=[]\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk.corpus\n",
        "for i in news:\n",
        "    pred_info={}\n",
        "    article = Article(i, language=\"en\") # en for English \n",
        "    article.download() \n",
        "    article.parse()\n",
        "    analysis=TextBlob(article.text)\n",
        "    polarity=analysis.sentiment.polarity\n",
        "    title_analysis=TextBlob(article.title)\n",
        "    pred_info['text']=article.text\n",
        "    pred_info['n_tokens_title']=len(tokenize(article.title))\n",
        "    pred_info['n_tokens_content']=len(tokenize(article.text))\n",
        "    pred_info['n_unique_tokens']=rate_unique(article.text)\n",
        "    pred_info['n_non_stop_words']=rate_nonstop(article.text)[0]\n",
        "    pred_info['n_non_stop_unique_tokens']=rate_nonstop(article.text)[1]\n",
        "    pred_info['num_hrefs']=article.html.count(\"https://timesofindia.indiatimes.com\")\n",
        "    pred_info['num_imgs']=len(article.images)\n",
        "    pred_info['num_videos']=len(article.movies)\n",
        "    pred_info['average_token_length']=avg_token(article.text)\n",
        "    pred_info['num_keywords']=len(article.keywords)\n",
        "    \n",
        "    if \"life-style\" in article.url:\n",
        "        pred_info['data_channel_is_lifestyle']=1\n",
        "    else:\n",
        "        pred_info['data_channel_is_lifestyle']=0\n",
        "    if \"etimes\" in article.url:\n",
        "        pred_info['data_channel_is_entertainment']=1\n",
        "    else:\n",
        "        pred_info['data_channel_is_entertainment']=0\n",
        "    if \"business\" in article.url:\n",
        "        pred_info['data_channel_is_bus']=1\n",
        "    else:\n",
        "        pred_info['data_channel_is_bus']=0\n",
        "    if \"social media\" or \"facebook\" or \"whatsapp\" in article.text.lower():\n",
        "        data_channel_is_socmed=1\n",
        "        data_channel_is_tech=0\n",
        "        data_channel_is_world=0\n",
        "    else:\n",
        "        data_channel_is_socmed=0\n",
        "    if (\"technology\" or \"tech\" in article.text.lower()) or (\"technology\" or \"tech\" in article.url):\n",
        "        data_channel_is_tech=1\n",
        "        data_channel_is_socmed=0\n",
        "        data_channel_is_world=0\n",
        "    else:\n",
        "        data_channel_is_tech=0\n",
        "    if \"world\" in article.url:\n",
        "        data_channel_is_world=1\n",
        "        data_channel_is_tech=0\n",
        "        data_channel_is_socmed=0\n",
        "    else:\n",
        "        data_channel_is_world=0\n",
        "        \n",
        "    pred_info['data_channel_is_socmed']=data_channel_is_socmed\n",
        "    pred_info['data_channel_is_tech']=data_channel_is_tech\n",
        "    pred_info['data_channel_is_world']=data_channel_is_world\n",
        "    \n",
        "    if day(i)==\"Monday\":\n",
        "        pred_info['weekday_is_monday']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_monday']=0\n",
        "    if day(i)==\"Tuesday\":\n",
        "        pred_info['weekday_is_tuesday']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_tuesday']=0\n",
        "    if day(i)==\"Wednesday\":\n",
        "        pred_info['weekday_is_wednesday']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_wednesday']=0\n",
        "    if day(i)==\"Thursday\":\n",
        "        pred_info['weekday_is_thursday']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_thursday']=0\n",
        "    if day(i)==\"Friday\":\n",
        "        pred_info['weekday_is_friday']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_friday']=0\n",
        "    if day(i)==\"Saturday\":\n",
        "        pred_info['weekday_is_saturday']=1\n",
        "        pred_info['is_weekend']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_saturday']=0\n",
        "    if day(i)==\"Sunday\":\n",
        "        pred_info['weekday_is_sunday']=1\n",
        "        pred_info['is_weekend']=1\n",
        "    else:\n",
        "        pred_info['weekday_is_sunday']=0\n",
        "        pred_info['is_weekend']=0\n",
        "        \n",
        "    pred_info['global_subjectivity']=analysis.sentiment.subjectivity\n",
        "    pred_info['global_sentiment_polarity']=analysis.sentiment.polarity\n",
        "    pred_info['global_rate_positive_words']=rates(article.text)[0]\n",
        "    pred_info['global_rate_negative_words']=rates(article.text)[1]\n",
        "    pred_info['avg_positive_polarity']=rates(article.text)[2]\n",
        "    pred_info['min_positive_polarity']=rates(article.text)[3]\n",
        "    pred_info['max_positive_polarity']=rates(article.text)[4]\n",
        "    pred_info['avg_negative_polarity']=rates(article.text)[5]\n",
        "    pred_info['min_negative_polarity']=rates(article.text)[6]\n",
        "    pred_info['max_negative_polarity']=rates(article.text)[7]    \n",
        "    pred_info['title_subjectivity']=title_analysis.sentiment.subjectivity\n",
        "    pred_info['title_sentiment_polarity']=title_analysis.sentiment.polarity\n",
        "    df2.append(pred_info)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-33cc43c3b745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpred_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_tokens_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpred_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_unique_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpred_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_non_stop_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate_nonstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mpred_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_non_stop_unique_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate_nonstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpred_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_hrefs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://timesofindia.indiatimes.com\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-5ec35695cf83>\u001b[0m in \u001b[0;36mrate_nonstop\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrate_nonstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mwords1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrate_nonstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mno_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-5ec35695cf83>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrate_nonstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mwords1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrate_nonstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mno_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'WordListCorpusReader' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfyWpPVvCMil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "5ce3883a-2958-49ea-8fe2-42f44c8196ad"
      },
      "source": [
        "pred_df=pd.DataFrame(df2)\n",
        "pred_test=pred_df.drop(['text'],axis=1)\n",
        "pred_df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>num_videos</th>\n",
              "      <th>average_token_length</th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>data_channel_is_lifestyle</th>\n",
              "      <th>data_channel_is_entertainment</th>\n",
              "      <th>data_channel_is_bus</th>\n",
              "      <th>data_channel_is_socmed</th>\n",
              "      <th>data_channel_is_tech</th>\n",
              "      <th>data_channel_is_world</th>\n",
              "      <th>weekday_is_monday</th>\n",
              "      <th>weekday_is_tuesday</th>\n",
              "      <th>weekday_is_wednesday</th>\n",
              "      <th>weekday_is_thursday</th>\n",
              "      <th>weekday_is_friday</th>\n",
              "      <th>weekday_is_saturday</th>\n",
              "      <th>weekday_is_sunday</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>global_subjectivity</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>global_rate_positive_words</th>\n",
              "      <th>global_rate_negative_words</th>\n",
              "      <th>avg_positive_polarity</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nurse Sandrine poses as she works in a hotel o...</td>\n",
              "      <td>12</td>\n",
              "      <td>559</td>\n",
              "      <td>0.583184</td>\n",
              "      <td>230</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>4.737030</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.426497</td>\n",
              "      <td>0.122980</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.317643</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.566667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.300000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apr 28, 2020, 08:40AM IST\\n\\nSource: AP\\n\\nThe...</td>\n",
              "      <td>15</td>\n",
              "      <td>152</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>185</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4.486842</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.342472</td>\n",
              "      <td>0.174148</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.327321</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.444444</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apr 28, 2020, 08:43AM IST\\n\\nSource: AP\\n\\nWit...</td>\n",
              "      <td>9</td>\n",
              "      <td>144</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>185</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4.472222</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.398452</td>\n",
              "      <td>0.010357</td>\n",
              "      <td>1.215</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.343759</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.323402</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apr 28, 2020, 08:39AM IST\\n\\nSource: AP\\n\\nNor...</td>\n",
              "      <td>14</td>\n",
              "      <td>181</td>\n",
              "      <td>0.662983</td>\n",
              "      <td>185</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.287167</td>\n",
              "      <td>0.074750</td>\n",
              "      <td>1.335</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.352916</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.302464</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Apr 27, 2020, 08:27AM IST\\n\\nSource: AP\\n\\nThe...</td>\n",
              "      <td>8</td>\n",
              "      <td>190</td>\n",
              "      <td>0.594737</td>\n",
              "      <td>185</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>3.726316</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.470</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.358811</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.300687</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  title_sentiment_polarity\n",
              "0  Nurse Sandrine poses as she works in a hotel o...  ...                      0.00\n",
              "1  Apr 28, 2020, 08:40AM IST\\n\\nSource: AP\\n\\nThe...  ...                      0.00\n",
              "2  Apr 28, 2020, 08:43AM IST\\n\\nSource: AP\\n\\nWit...  ...                      0.00\n",
              "3  Apr 28, 2020, 08:39AM IST\\n\\nSource: AP\\n\\nNor...  ...                      0.91\n",
              "4  Apr 27, 2020, 08:27AM IST\\n\\nSource: AP\\n\\nThe...  ...                      0.00\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjRM3L1QQp4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "48a6c6c0-b536-46bc-99c0-563e34ca803d"
      },
      "source": [
        "test2=pd.DataFrame(clf.predict(pred_test),pred_df['text'])\n",
        "test2.reset_index(level=0, inplace=True)\n",
        "test2 = test2.rename(index=str, columns={\"index\": \"News\", 0: \"Virality\"})\n",
        "test2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-83e5cb5767e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"News\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Virality\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 36 and input n_features is 34 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS8KlhWRQx6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}